{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "3482cbc5-a883-4652-897f-71cbc45c8fa9",
      "metadata": {
        "id": "3482cbc5-a883-4652-897f-71cbc45c8fa9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrNNlxdr-4h_",
        "outputId": "4adff78c-979d-4d28-fc3d-6d38b36fd24e"
      },
      "id": "DrNNlxdr-4h_",
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "0982fbc2-d99a-48ee-9f4e-826f191afbce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0982fbc2-d99a-48ee-9f4e-826f191afbce",
        "outputId": "b936d372-5271-4c26-8ef6-01c5c6a2df99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-159-e48e0c66f557>:1: DtypeWarning: Columns (108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/My Drive/male_players (legacy).csv') #df with Columns: 110 entries\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/male_players (legacy).csv') #df with Columns: 110 entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "8ef665f8-54a4-453d-ba72-a1a1114f96f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ef665f8-54a4-453d-ba72-a1a1114f96f0",
        "outputId": "70107fb6-6eef-4152-d387-27a7fa9c15b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11969 entries, 0 to 11968\n",
            "Columns: 110 entries, player_id to player_face_url\n",
            "dtypes: float64(59), int64(4), object(47)\n",
            "memory usage: 10.0+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data preprocessing**"
      ],
      "metadata": {
        "id": "phoddtD0QjMw"
      },
      "id": "phoddtD0QjMw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dropping Columns with too many Null Values**"
      ],
      "metadata": {
        "id": "lTiQGo0QQnPq"
      },
      "id": "lTiQGo0QQnPq"
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "10e532ca-0a12-4db1-9b49-ffa83546522a",
      "metadata": {
        "id": "10e532ca-0a12-4db1-9b49-ffa83546522a"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    # Dropping columns with more than 1/3 NA's\n",
        "    for column in df.columns:\n",
        "        na_count = df[column].isna().sum()\n",
        "        if na_count > (len(df) / 3):\n",
        "            df.drop(column, axis='columns', inplace=True)\n",
        "\n",
        "    # Dropping the first 7 columns\n",
        "    df = df.iloc[:, 7:]\n",
        "\n",
        "    # Dropping specific features\n",
        "    columns_to_drop = [\n",
        "        'league_name', 'league_level', 'club_team_id', 'club_name',\n",
        "        'club_position', 'club_jersey_number', 'club_joined_date',\n",
        "        'club_contract_valid_until_year', 'nationality_id', 'nationality_name',\n",
        "        'real_face', 'player_positions', 'dob', 'work_rate', 'body_type'\n",
        "    ]\n",
        "    df.drop(columns=columns_to_drop, axis='columns', inplace=True)\n",
        "\n",
        "    # Dropping the last 28 columns\n",
        "    df = df.iloc[:, :-28]\n",
        "\n",
        "    # Handling 'preferred_foot'\n",
        "    preferred_foot = df['preferred_foot']\n",
        "    df.drop('preferred_foot', axis=1, inplace=True)\n",
        "\n",
        "    # Dropping columns with less than 0.5 correlation with overall score\n",
        "    corr_matrix = df.corr()\n",
        "    sorted_correlations = corr_matrix['overall'].sort_values(ascending=False)\n",
        "    columns_to_drop = sorted_correlations[sorted_correlations < 0.5].index.tolist()\n",
        "    df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "    # Adding 'preferred_foot' back\n",
        "    df['preferred_foot'] = preferred_foot\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = preprocess_data(df)"
      ],
      "metadata": {
        "id": "d4-znPi_GAOZ"
      },
      "id": "d4-znPi_GAOZ",
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LAUoqWbGceN",
        "outputId": "5bd4e99e-1542-40e9-a427-0b5375fd6b97"
      },
      "id": "3LAUoqWbGceN",
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11969 entries, 0 to 11968\n",
            "Data columns (total 8 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   overall                   11969 non-null  int64  \n",
            " 1   potential                 11968 non-null  float64\n",
            " 2   value_eur                 11699 non-null  float64\n",
            " 3   wage_eur                  11765 non-null  float64\n",
            " 4   international_reputation  11968 non-null  float64\n",
            " 5   passing                   10795 non-null  float64\n",
            " 6   movement_reactions        11968 non-null  float64\n",
            " 7   preferred_foot            11968 non-null  object \n",
            "dtypes: float64(6), int64(1), object(1)\n",
            "memory usage: 748.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Imputing the data**"
      ],
      "metadata": {
        "id": "tJ-ZqJ2GV_Yp"
      },
      "id": "tJ-ZqJ2GV_Yp"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "def impute_missing_values(df):\n",
        "    # Splitting numeric and non-numeric data\n",
        "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "    nonnumeric_cols = df.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "    # Impute na's that are numeric\n",
        "    imputer = SimpleImputer(strategy=\"median\")\n",
        "    imputed_numeric = pd.DataFrame(imputer.fit_transform(df[numeric_cols]), columns=numeric_cols)\n",
        "\n",
        "    # Impute na's that are non-numeric\n",
        "    imputer_str = SimpleImputer(strategy=\"most_frequent\")\n",
        "    imputed_nonnumeric = pd.DataFrame(imputer_str.fit_transform(df[nonnumeric_cols]), columns=nonnumeric_cols)\n",
        "\n",
        "    # Concatenate the imputed numeric and nonnumeric\n",
        "    imputed_df = pd.concat([imputed_numeric, imputed_nonnumeric], axis=1)\n",
        "\n",
        "    # Return the imputed DataFrame\n",
        "    return pd.DataFrame(imputed_df, columns=df.columns)"
      ],
      "metadata": {
        "id": "9pfzB0JPRtUK"
      },
      "id": "9pfzB0JPRtUK",
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = impute_missing_values(df)"
      ],
      "metadata": {
        "id": "irf7tEmfIj7r"
      },
      "id": "irf7tEmfIj7r",
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Label encoding the data**"
      ],
      "metadata": {
        "id": "sRjuURjdZpYy"
      },
      "id": "sRjuURjdZpYy"
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def encode_preferred_foot(df):\n",
        "    # Create a LabelEncoder object\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Extract 'preferred_foot' values and encode them\n",
        "    values = np.array(df['preferred_foot'])\n",
        "    integer_encoded = label_encoder.fit_transform(values)\n",
        "\n",
        "    # Drop the original 'preferred_foot' column\n",
        "    df.drop('preferred_foot', axis=1, inplace=True)\n",
        "\n",
        "    # Add the integer encoded 'preferred_foot' column back to the DataFrame\n",
        "    df['preferred_foot'] = integer_encoded\n",
        "\n",
        "    with open('preferred_foot_encoder.pkl', 'wb') as f:\n",
        "        pickle.dump(label_encoder, f)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "OEYJ-Qgvb82x"
      },
      "id": "OEYJ-Qgvb82x",
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = encode_preferred_foot(df)"
      ],
      "metadata": {
        "id": "7uL1-S2AIypy"
      },
      "id": "7uL1-S2AIypy",
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Standard Scaling**"
      ],
      "metadata": {
        "id": "Djkhy6z4BOyT"
      },
      "id": "Djkhy6z4BOyT"
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "200402af-9668-4554-b88a-c64ce0dbf83a",
      "metadata": {
        "id": "200402af-9668-4554-b88a-c64ce0dbf83a"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def prepare_features_and_target(df):\n",
        "    # Selecting features and target\n",
        "    X = df.drop(['overall'], axis=1)\n",
        "    y = df['overall']\n",
        "\n",
        "    # Standard Scaling\n",
        "    sc = StandardScaler()\n",
        "    X_scaled = sc.fit_transform(X)\n",
        "\n",
        "    return X_scaled, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "b9eaed0d-0904-4b47-b2d0-8379d9fd5519",
      "metadata": {
        "id": "b9eaed0d-0904-4b47-b2d0-8379d9fd5519"
      },
      "outputs": [],
      "source": [
        "X, y = prepare_features_and_target(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training models**\n",
        "\n"
      ],
      "metadata": {
        "id": "XFIEVWi3BhTT"
      },
      "id": "XFIEVWi3BhTT"
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "5aef2c49-0312-451d-b5af-d79f9997acb8",
      "metadata": {
        "id": "5aef2c49-0312-451d-b5af-d79f9997acb8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "626bf4e2-4537-4ee9-8e3f-57f1ee557782",
      "metadata": {
        "id": "626bf4e2-4537-4ee9-8e3f-57f1ee557782"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def train_and_evaluate_models(Xtrain, Ytrain, Xtest, Ytest):\n",
        "    models = {\n",
        "        'RandomForestRegressor': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "        'XGBRegressor': XGBRegressor(objective='reg:squarederror', random_state=42),\n",
        "        'GradientBoostingRegressor': GradientBoostingRegressor(random_state=42)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Train the model\n",
        "        model.fit(Xtrain, Ytrain)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(Xtest)\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse = mean_squared_error(Ytest, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(Ytest, y_pred)\n",
        "        r2 = r2_score(Ytest, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results[name] = {\n",
        "            'model': model,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2\n",
        "        }\n",
        "\n",
        "        # Print results\n",
        "        print(f\"\\nResults for {name}:\")\n",
        "        print(f\"Root Mean Square Error: {rmse}\")\n",
        "        print(f\"Mean Absolute Error: {mae}\")\n",
        "        print(f\"R2 Score: {r2}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = train_and_evaluate_models(Xtrain, Ytrain, Xtest, Ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yjp8FBKLp6s",
        "outputId": "76926d39-1489-4892-9b30-2b23909b0500"
      },
      "id": "_yjp8FBKLp6s",
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for RandomForestRegressor:\n",
            "Root Mean Square Error: 0.9785906156422566\n",
            "Mean Absolute Error: 0.6143547360464654\n",
            "R2 Score: 0.9670659223313272\n",
            "\n",
            "Results for XGBRegressor:\n",
            "Root Mean Square Error: 0.9946746277989036\n",
            "Mean Absolute Error: 0.667246209051376\n",
            "R2 Score: 0.9659744235100505\n",
            "\n",
            "Results for GradientBoostingRegressor:\n",
            "Root Mean Square Error: 1.0925285207580862\n",
            "Mean Absolute Error: 0.7783317068402139\n",
            "R2 Score: 0.9589503953953633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Grid Search with Cross Validation**"
      ],
      "metadata": {
        "id": "zL5vx9nKHDqz"
      },
      "id": "zL5vx9nKHDqz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gradient Boosting Regressor**"
      ],
      "metadata": {
        "id": "zeLGdwnXAzjt"
      },
      "id": "zeLGdwnXAzjt"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pickle as pkl\n",
        "import os\n",
        "\n",
        "# Setting up cross-validation and model parameters\n",
        "cv = KFold(n_splits=3)\n",
        "gbr = GradientBoostingRegressor(random_state=42)\n",
        "PARAMETERS_gb = {\n",
        "    \"max_depth\": [2, 5, 6],\n",
        "    \"learning_rate\": [0.3, 0.1, 0.03],\n",
        "    \"n_estimators\": [100, 500, 1000]\n",
        "}\n",
        "\n",
        "# Performing grid search with cross-validation\n",
        "model_gs = GridSearchCV(gbr, param_grid=PARAMETERS_gb, cv=cv, scoring=\"neg_mean_squared_error\")\n",
        "model_gs.fit(Xtrain, Ytrain)\n",
        "\n",
        "# Saving the model\n",
        "model_filename = 'GradientBoostingRegressor_GridSearch.pkl'\n",
        "try:\n",
        "    with open(model_filename, 'wb') as file:\n",
        "        pkl.dump(model_gs, file)\n",
        "    print(f\"Model saved successfully as {model_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the model: {e}\")\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model_gs.predict(Xtest)\n",
        "\n",
        "# Printing regression metrics\n",
        "print(model_gs.best_estimator_.__class__.__name__)\n",
        "print(\"Best parameters found: \", model_gs.best_params_)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(Ytest, y_pred))\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error(Ytest, y_pred))\n",
        "print(\"R^2 Score:\", r2_score(Ytest, y_pred))\n",
        "\n",
        "# Verifying if the file was created\n",
        "if os.path.exists(model_filename):\n",
        "    print(f\"File {model_filename} exists.\")\n",
        "    print(f\"File size: {os.path.getsize(model_filename)} bytes\")\n",
        "else:\n",
        "    print(f\"File {model_filename} does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzJQcSbY8PQH",
        "outputId": "656b639a-4ba3-4771-9fa7-d5927f226e80"
      },
      "id": "LzJQcSbY8PQH",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully as GradientBoostingRegressor_GridSearch.pkl\n",
            "GradientBoostingRegressor\n",
            "Best parameters found:  {'learning_rate': 0.03, 'max_depth': 5, 'n_estimators': 1000}\n",
            "Mean Squared Error: 0.950367113815074\n",
            "Mean Absolute Error: 0.6640856444619391\n",
            "R^2 Score: 0.9673160293620156\n",
            "File GradientBoostingRegressor_GridSearch.pkl exists.\n",
            "File size: 3899323 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **XGB Regressor**"
      ],
      "metadata": {
        "id": "Jx4oMiSfMeX6"
      },
      "id": "Jx4oMiSfMeX6"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "import pickle as pkl\n",
        "import os\n",
        "\n",
        "# Setting up cross-validation and model parameters\n",
        "cv = KFold(n_splits=3)\n",
        "xgbr = XGBRegressor(random_state=42)\n",
        "PARAMETERS_xgb = {\n",
        "    \"max_depth\": [2, 5, 6],\n",
        "    \"learning_rate\": [0.3, 0.1, 0.03],\n",
        "    \"min_child_weight\": [1,5,15],\n",
        "    \"n_estimators\": [100, 500, 1000]\n",
        "}\n",
        "\n",
        "# Performing grid search with cross-validation\n",
        "model_gs = GridSearchCV(xgbr, param_grid=PARAMETERS_xgb, cv=cv, scoring=\"neg_mean_squared_error\")\n",
        "model_gs.fit(Xtrain, Ytrain)\n",
        "\n",
        "# Saving the model\n",
        "model_filename = 'XGBRegressor_GridSearch.pkl'\n",
        "try:\n",
        "    with open(model_filename, 'wb') as file:\n",
        "        pkl.dump(model_gs, file)\n",
        "    print(f\"Model saved successfully as {model_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the model: {e}\")\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model_gs.predict(Xtest)\n",
        "\n",
        "# Printing regression metrics\n",
        "print(model_gs.best_estimator_.__class__.__name__)\n",
        "print(\"Best parameters found: \", model_gs.best_params_)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(Ytest, y_pred))\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error(Ytest, y_pred))\n",
        "print(\"R^2 Score:\", r2_score(Ytest, y_pred))\n",
        "\n",
        "# Verifying if the file was created\n",
        "if os.path.exists(model_filename):\n",
        "    print(f\"File {model_filename} exists.\")\n",
        "    print(f\"File size: {os.path.getsize(model_filename)} bytes\")\n",
        "else:\n",
        "    print(f\"File {model_filename} does not exist.\")"
      ],
      "metadata": {
        "id": "TAHLYagvCqqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675e16a5-d404-42fa-c635-3d090aedb754"
      },
      "id": "TAHLYagvCqqI",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully as XGBRegressor_GridSearch.pkl\n",
            "XGBRegressor\n",
            "Best parameters found:  {'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 1000}\n",
            "Mean Squared Error: 0.9371518515556908\n",
            "Mean Absolute Error: 0.6505846630660513\n",
            "R^2 Score: 0.9677705139894612\n",
            "File XGBRegressor_GridSearch.pkl exists.\n",
            "File size: 3869565 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RandomForest Regressor**"
      ],
      "metadata": {
        "id": "V5w0inGoM_rk"
      },
      "id": "V5w0inGoM_rk"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pickle as pkl\n",
        "import os\n",
        "\n",
        "# Setting up cross-validation and model parameters\n",
        "cv = KFold(n_splits=3)\n",
        "rfr = RandomForestRegressor(random_state=42)\n",
        "PARAMETERS_rf = {\n",
        "    \"max_depth\": [2, 5, 6],\n",
        "    \"n_estimators\": [100, 500, 1000],\n",
        "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "# Performing grid search with cross-validation\n",
        "model_gs = GridSearchCV(rfr, param_grid=PARAMETERS_rf, cv=cv, scoring=\"neg_mean_squared_error\")\n",
        "model_gs.fit(Xtrain, Ytrain)\n",
        "\n",
        "# Saving the model\n",
        "model_filename = 'RandomForestRegressor_GridSearch.pkl'\n",
        "try:\n",
        "    with open(model_filename, 'wb') as file:\n",
        "        pkl.dump(model_gs, file)\n",
        "    print(f\"Model saved successfully as {model_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the model: {e}\")\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model_gs.predict(Xtest)\n",
        "\n",
        "# Printing regression metrics\n",
        "print(model_gs.best_estimator_.__class__.__name__)\n",
        "print(\"Best parameters found: \", model_gs.best_params_)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(Ytest, y_pred))\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error(Ytest, y_pred))\n",
        "print(\"R^2 Score:\", r2_score(Ytest, y_pred))\n",
        "\n",
        "# Verifying if the file was created\n",
        "if os.path.exists(model_filename):\n",
        "    print(f\"File {model_filename} exists.\")\n",
        "    print(f\"File size: {os.path.getsize(model_filename)} bytes\")\n",
        "else:\n",
        "    print(f\"File {model_filename} does not exist.\")"
      ],
      "metadata": {
        "id": "odV48slnENiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7470bdc5-2879-4d09-f04a-c09bb21613b4"
      },
      "id": "odV48slnENiV",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully as RandomForestRegressor_GridSearch.pkl\n",
            "RandomForestRegressor\n",
            "Best parameters found:  {'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
            "Mean Squared Error: 1.3769552495922106\n",
            "Mean Absolute Error: 0.8591297291659842\n",
            "R^2 Score: 0.9526452838137163\n",
            "File RandomForestRegressor_GridSearch.pkl exists.\n",
            "File size: 8274166 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training again on the best model**"
      ],
      "metadata": {
        "id": "Q7wXFNErayX6"
      },
      "id": "Q7wXFNErayX6"
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "import pickle as pkl\n",
        "\n",
        "# Create the best XGBoost model with the optimal parameters\n",
        "best_xgb_model = XGBRegressor(\n",
        "    learning_rate=0.03,\n",
        "    max_depth=6,\n",
        "    n_estimators=1000,\n",
        "    min_child_weight= 1,\n",
        "    random_state=42  # for reproducibility\n",
        ")\n",
        "\n",
        "# Fit the model on the entire training data\n",
        "best_xgb_model.fit(Xtrain, Ytrain)\n",
        "\n",
        "# Save the model\n",
        "best_model_filename = 'Best_XGBRegressor.pkl'\n",
        "try:\n",
        "    with open(best_model_filename, 'wb') as file:\n",
        "        pkl.dump(best_xgb_model, file)\n",
        "    print(f\"Best model saved successfully as {best_model_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the best model: {e}\")\n",
        "\n",
        "# Verify if the file was created\n",
        "import os\n",
        "if os.path.exists(best_model_filename):\n",
        "    print(f\"File {best_model_filename} exists.\")\n",
        "    print(f\"File size: {os.path.getsize(best_model_filename)} bytes\")\n",
        "else:\n",
        "    print(f\"File {best_model_filename} does not exist.\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_pred_best = best_xgb_model.predict(Xtest)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Calculate and print metrics\n",
        "mse = mean_squared_error(Ytest, y_pred_best)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(Ytest, y_pred_best)\n",
        "r2 = r2_score(Ytest, y_pred_best)\n",
        "\n",
        "print(\"\\nBest XGBoost Model Performance:\")\n",
        "print(f\"Root Mean Square Error: {rmse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUurb8gSa2kM",
        "outputId": "1f3bb76c-65ed-45fd-8dc4-f01068958926"
      },
      "id": "lUurb8gSa2kM",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved successfully as Best_XGBRegressor.pkl\n",
            "File Best_XGBRegressor.pkl exists.\n",
            "File size: 3857687 bytes\n",
            "\n",
            "Best XGBoost Model Performance:\n",
            "Root Mean Square Error: 0.9680660367741918\n",
            "Mean Absolute Error: 0.6505846630660513\n",
            "R^2 Score: 0.9677705139894612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing with players_22 data**"
      ],
      "metadata": {
        "id": "wHHKGCaQWYH2"
      },
      "id": "wHHKGCaQWYH2"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the new data\n",
        "players = pd.read_csv('/content/drive/My Drive/players_22.csv') #df with Columns: 110 entries)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kAhhFaaWevi",
        "outputId": "b7013f9b-310b-410e-be90-a96a78f44f62"
      },
      "id": "0kAhhFaaWevi",
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-173-a50ce2352cba>:4: DtypeWarning: Columns (25,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  players = pd.read_csv('/content/drive/My Drive/players_22.csv') #df with Columns: 110 entries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the columns that are in df but not in new_data\n",
        "columns_to_keep = [col for col in df.columns if col in players.columns]\n",
        "\n",
        "# Keep only these columns in new_data\n",
        "players = players[columns_to_keep]"
      ],
      "metadata": {
        "id": "N90dwRjaZH-E"
      },
      "id": "N90dwRjaZH-E",
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "players = impute_missing_values(players)"
      ],
      "metadata": {
        "id": "MxyB9i8BW26_"
      },
      "id": "MxyB9i8BW26_",
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Extract 'preferred_foot' values and encode them\n",
        "values = np.array(players['preferred_foot'])\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "\n",
        "# Drop the original 'preferred_foot' column\n",
        "players.drop('preferred_foot', axis=1, inplace=True)\n",
        "\n",
        "# Add the integer encoded 'preferred_foot' column back to the DataFrame\n",
        "players['preferred_foot'] = integer_encoded"
      ],
      "metadata": {
        "id": "dezctCfw4s29"
      },
      "id": "dezctCfw4s29",
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features (X) and target (y) for the new data\n",
        "X_new = players.drop(['overall'], axis=1)\n",
        "y_new = players['overall']"
      ],
      "metadata": {
        "id": "gxZJmtolXkAP"
      },
      "id": "gxZJmtolXkAP",
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply standard scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_new_scaled = sc.fit_transform(X_new)"
      ],
      "metadata": {
        "id": "AgrNbvR3zFQj"
      },
      "id": "AgrNbvR3zFQj",
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "\n",
        "# Load the models\n",
        "with open('Best_XGBRegressor.pkl', 'rb') as file:\n",
        "    best_model = pkl.load(file)\n",
        "\n",
        "# Make predictions\n",
        "xgb_predictions = best_model.predict(X_new_scaled)"
      ],
      "metadata": {
        "id": "MLFxm3qtW9Bb"
      },
      "id": "MLFxm3qtW9Bb",
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_new, xgb_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_new, xgb_predictions)\n",
        "r2 = r2_score(y_new, xgb_predictions)\n",
        "\n",
        "print(f\"\\nResults for XGBoost:\")\n",
        "print(f\"Root Mean Square Error: {rmse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R2 Score: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7hGOHm0W-EK",
        "outputId": "8569bc5f-f9f2-428d-8b97-d1c46bf9ac57"
      },
      "id": "S7hGOHm0W-EK",
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for XGBoost:\n",
            "Root Mean Square Error: 3.87950946110754\n",
            "Mean Absolute Error: 2.8352580859399747\n",
            "R2 Score: 0.6820417474070294\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tJ-ZqJ2GV_Yp",
        "Djkhy6z4BOyT",
        "XFIEVWi3BhTT",
        "zL5vx9nKHDqz",
        "Jx4oMiSfMeX6",
        "V5w0inGoM_rk",
        "Q7wXFNErayX6"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}