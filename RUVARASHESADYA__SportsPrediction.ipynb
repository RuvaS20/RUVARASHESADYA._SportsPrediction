{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3482cbc5-a883-4652-897f-71cbc45c8fa9",
      "metadata": {
        "id": "3482cbc5-a883-4652-897f-71cbc45c8fa9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrNNlxdr-4h_",
        "outputId": "efe8201d-327c-4ead-cd44-c13f5e7a6241"
      },
      "id": "DrNNlxdr-4h_",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0982fbc2-d99a-48ee-9f4e-826f191afbce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0982fbc2-d99a-48ee-9f4e-826f191afbce",
        "outputId": "4f0905f5-ceee-4bc8-9cc9-4c38600a6a1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e48e0c66f557>:1: DtypeWarning: Columns (108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('/content/drive/My Drive/male_players (legacy).csv') #df with Columns: 110 entries\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/male_players (legacy).csv') #df with Columns: 110 entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8ef665f8-54a4-453d-ba72-a1a1114f96f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ef665f8-54a4-453d-ba72-a1a1114f96f0",
        "outputId": "81abc677-b396-4345-ce93-45ec2399893e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11969 entries, 0 to 11968\n",
            "Columns: 110 entries, player_id to player_face_url\n",
            "dtypes: float64(59), int64(4), object(47)\n",
            "memory usage: 10.0+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data preprocessing**"
      ],
      "metadata": {
        "id": "phoddtD0QjMw"
      },
      "id": "phoddtD0QjMw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dropping Columns with too many Null Values**"
      ],
      "metadata": {
        "id": "lTiQGo0QQnPq"
      },
      "id": "lTiQGo0QQnPq"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "10e532ca-0a12-4db1-9b49-ffa83546522a",
      "metadata": {
        "id": "10e532ca-0a12-4db1-9b49-ffa83546522a"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    # Dropping columns with more than 1/3 NA's\n",
        "    for column in df.columns:\n",
        "        na_count = df[column].isna().sum()\n",
        "        if na_count > (len(df) / 3):\n",
        "            df.drop(column, axis='columns', inplace=True)\n",
        "\n",
        "    # Dropping the first 7 columns\n",
        "    df = df.iloc[:, 7:]\n",
        "\n",
        "    # Dropping specific features\n",
        "    columns_to_drop = [\n",
        "        'league_name', 'league_level', 'club_team_id', 'club_name',\n",
        "        'club_position', 'club_jersey_number', 'club_joined_date',\n",
        "        'club_contract_valid_until_year', 'nationality_id', 'nationality_name',\n",
        "        'real_face', 'player_positions', 'dob', 'work_rate', 'body_type'\n",
        "    ]\n",
        "    df.drop(columns=columns_to_drop, axis='columns', inplace=True)\n",
        "\n",
        "    # Dropping the last 28 columns\n",
        "    df = df.iloc[:, :-28]\n",
        "\n",
        "    # Handling 'preferred_foot'\n",
        "    preferred_foot = df['preferred_foot']\n",
        "    df.drop('preferred_foot', axis=1, inplace=True)\n",
        "\n",
        "    # Dropping columns with less than 0.5 correlation with overall score\n",
        "    corr_matrix = df.corr()\n",
        "    sorted_correlations = corr_matrix['overall'].sort_values(ascending=False)\n",
        "    columns_to_drop = sorted_correlations[sorted_correlations < 0.5].index.tolist()\n",
        "    df.drop(columns=columns_to_drop, inplace=True)\n",
        "\n",
        "    # Adding 'preferred_foot' back\n",
        "    df['preferred_foot'] = preferred_foot\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = preprocess_data(df)"
      ],
      "metadata": {
        "id": "d4-znPi_GAOZ"
      },
      "id": "d4-znPi_GAOZ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LAUoqWbGceN",
        "outputId": "130fd5f4-127a-4f19-9cee-2d5cb485f7cc"
      },
      "id": "3LAUoqWbGceN",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11969 entries, 0 to 11968\n",
            "Data columns (total 8 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   overall                   11969 non-null  int64  \n",
            " 1   potential                 11968 non-null  float64\n",
            " 2   value_eur                 11699 non-null  float64\n",
            " 3   wage_eur                  11765 non-null  float64\n",
            " 4   international_reputation  11968 non-null  float64\n",
            " 5   passing                   10795 non-null  float64\n",
            " 6   movement_reactions        11968 non-null  float64\n",
            " 7   preferred_foot            11968 non-null  object \n",
            "dtypes: float64(6), int64(1), object(1)\n",
            "memory usage: 748.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Imputing the data**"
      ],
      "metadata": {
        "id": "tJ-ZqJ2GV_Yp"
      },
      "id": "tJ-ZqJ2GV_Yp"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "def impute_missing_values(df):\n",
        "    # Splitting numeric and non-numeric data\n",
        "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "    nonnumeric_cols = df.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "    # Impute na's that are numeric\n",
        "    imputer = SimpleImputer(strategy=\"median\")\n",
        "    imputed_numeric = pd.DataFrame(imputer.fit_transform(df[numeric_cols]), columns=numeric_cols)\n",
        "\n",
        "    # Impute na's that are non-numeric\n",
        "    imputer_str = SimpleImputer(strategy=\"most_frequent\")\n",
        "    imputed_nonnumeric = pd.DataFrame(imputer_str.fit_transform(df[nonnumeric_cols]), columns=nonnumeric_cols)\n",
        "\n",
        "    # Concatenate the imputed numeric and nonnumeric\n",
        "    imputed_df = pd.concat([imputed_numeric, imputed_nonnumeric], axis=1)\n",
        "\n",
        "    # Return the imputed DataFrame\n",
        "    return pd.DataFrame(imputed_df, columns=df.columns)"
      ],
      "metadata": {
        "id": "9pfzB0JPRtUK"
      },
      "id": "9pfzB0JPRtUK",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = impute_missing_values(df)"
      ],
      "metadata": {
        "id": "irf7tEmfIj7r"
      },
      "id": "irf7tEmfIj7r",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Label encoding the data**"
      ],
      "metadata": {
        "id": "sRjuURjdZpYy"
      },
      "id": "sRjuURjdZpYy"
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle as pkl\n",
        "\n",
        "def encode_preferred_foot(df):\n",
        "    # Create a LabelEncoder object\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Extract 'preferred_foot' values and encode them\n",
        "    values = np.array(df['preferred_foot'])\n",
        "    integer_encoded = label_encoder.fit_transform(values)\n",
        "\n",
        "    # Drop the original 'preferred_foot' column\n",
        "    df.drop('preferred_foot', axis=1, inplace=True)\n",
        "\n",
        "    # Add the integer encoded 'preferred_foot' column back to the DataFrame\n",
        "    df['preferred_foot'] = integer_encoded\n",
        "\n",
        "    with open('preferred_foot_encoder.pkl', 'wb') as f:\n",
        "        pkl.dump(label_encoder, f)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "OEYJ-Qgvb82x"
      },
      "id": "OEYJ-Qgvb82x",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = encode_preferred_foot(df)"
      ],
      "metadata": {
        "id": "7uL1-S2AIypy"
      },
      "id": "7uL1-S2AIypy",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Standard Scaling**"
      ],
      "metadata": {
        "id": "Djkhy6z4BOyT"
      },
      "id": "Djkhy6z4BOyT"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "200402af-9668-4554-b88a-c64ce0dbf83a",
      "metadata": {
        "id": "200402af-9668-4554-b88a-c64ce0dbf83a"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def prepare_features_and_target(df):\n",
        "    # Selecting features and target\n",
        "    X = df.drop(['overall'], axis=1)\n",
        "    y = df['overall']\n",
        "\n",
        "    # Standard Scaling\n",
        "    sc = StandardScaler()\n",
        "    X_scaled = sc.fit_transform(X)\n",
        "\n",
        "    return X_scaled, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b9eaed0d-0904-4b47-b2d0-8379d9fd5519",
      "metadata": {
        "id": "b9eaed0d-0904-4b47-b2d0-8379d9fd5519"
      },
      "outputs": [],
      "source": [
        "X, y = prepare_features_and_target(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training models**\n",
        "\n"
      ],
      "metadata": {
        "id": "XFIEVWi3BhTT"
      },
      "id": "XFIEVWi3BhTT"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5aef2c49-0312-451d-b5af-d79f9997acb8",
      "metadata": {
        "id": "5aef2c49-0312-451d-b5af-d79f9997acb8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "626bf4e2-4537-4ee9-8e3f-57f1ee557782",
      "metadata": {
        "id": "626bf4e2-4537-4ee9-8e3f-57f1ee557782"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def train_and_evaluate_models(Xtrain, Ytrain, Xtest, Ytest):\n",
        "    models = {\n",
        "        'RandomForestRegressor': RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            random_state=42,\n",
        "            max_depth=10,  # Limit tree depth\n",
        "            min_samples_split=5,  # Require more samples to split a node\n",
        "            min_samples_leaf=2  # Require more samples in leaf nodes\n",
        "        ),\n",
        "        'XGBRegressor': XGBRegressor(\n",
        "            objective='reg:squarederror',\n",
        "            random_state=42,\n",
        "            max_depth=6,  # Limit tree depth\n",
        "            learning_rate=0.01,  # Lower learning rate\n",
        "            n_estimators=1000,  # Increase number of trees\n",
        "            reg_alpha=0.1,  # L1 regularization\n",
        "            reg_lambda=1,  # L2 regularization\n",
        "            subsample=0.8,  # Use 80% of data per tree\n",
        "            colsample_bytree=0.8  # Use 80% of features per tree\n",
        "        ),\n",
        "        'GradientBoostingRegressor': GradientBoostingRegressor(\n",
        "            random_state=42,\n",
        "            n_estimators=100,\n",
        "            max_depth=5,  # Limit tree depth\n",
        "            learning_rate=0.1,\n",
        "            subsample=0.8,  # Use 80% of data per tree\n",
        "            min_samples_split=5,  # Require more samples to split a node\n",
        "            min_samples_leaf=2  # Require more samples in leaf nodes\n",
        "        )\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Train the model\n",
        "        model.fit(Xtrain, Ytrain)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(Xtest)\n",
        "\n",
        "        # Calculate metrics\n",
        "        mse = mean_squared_error(Ytest, y_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(Ytest, y_pred)\n",
        "        r2 = r2_score(Ytest, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results[name] = {\n",
        "            'model': model,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2\n",
        "        }\n",
        "\n",
        "        # Print results\n",
        "        print(f\"\\nResults for {name}:\")\n",
        "        print(f\"Root Mean Square Error: {rmse}\")\n",
        "        print(f\"Mean Absolute Error: {mae}\")\n",
        "        print(f\"R2 Score: {r2}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = train_and_evaluate_models(Xtrain, Ytrain, Xtest, Ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yjp8FBKLp6s",
        "outputId": "d7fd9c4a-d133-4026-d599-c1f0645d75ad"
      },
      "id": "_yjp8FBKLp6s",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for RandomForestRegressor:\n",
            "Root Mean Square Error: 1.019108282577096\n",
            "Mean Absolute Error: 0.6667764442129046\n",
            "R2 Score: 0.9642822515420381\n",
            "\n",
            "Results for XGBRegressor:\n",
            "Root Mean Square Error: 0.981186127750187\n",
            "Mean Absolute Error: 0.6771645302959751\n",
            "R2 Score: 0.9668909887969592\n",
            "\n",
            "Results for GradientBoostingRegressor:\n",
            "Root Mean Square Error: 1.0073591856715296\n",
            "Mean Absolute Error: 0.6949948054258194\n",
            "R2 Score: 0.9651010698302517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Grid Search with Cross Validation**"
      ],
      "metadata": {
        "id": "zL5vx9nKHDqz"
      },
      "id": "zL5vx9nKHDqz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gradient Boosting Regressor**"
      ],
      "metadata": {
        "id": "zeLGdwnXAzjt"
      },
      "id": "zeLGdwnXAzjt"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pickle as pkl\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Setting up cross-validation and model parameters\n",
        "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "gbr = GradientBoostingRegressor(random_state=42)\n",
        "PARAMETERS_gb = {\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.3],\n",
        "    \"n_estimators\": [100, 500, 1000],\n",
        "    \"max_features\": ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Performing grid search with cross-validation\n",
        "model_gs = GridSearchCV(gbr, param_grid=PARAMETERS_gb, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=2)\n",
        "model_gs.fit(Xtrain, Ytrain)\n",
        "\n",
        "# Saving the model\n",
        "model_filename = 'GradientBoostingRegressor_GridSearch.pkl'\n",
        "try:\n",
        "    with open(model_filename, 'wb') as file:\n",
        "        pkl.dump(model_gs, file)\n",
        "    print(f\"Model saved successfully as {model_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the model: {e}\")\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model_gs.predict(Xtest)\n",
        "\n",
        "# Printing regression metrics\n",
        "print(model_gs.best_estimator_.__class__.__name__)\n",
        "print(\"Best parameters found: \", model_gs.best_params_)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(Ytest, y_pred))\n",
        "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(Ytest, y_pred)))\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error(Ytest, y_pred))\n",
        "print(\"R^2 Score:\", r2_score(Ytest, y_pred))\n",
        "\n",
        "# Verifying if the file was created\n",
        "if os.path.exists(model_filename):\n",
        "    print(f\"File {model_filename} exists.\")\n",
        "    print(f\"File size: {os.path.getsize(model_filename)} bytes\")\n",
        "else:\n",
        "    print(f\"File {model_filename} does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzJQcSbY8PQH",
        "outputId": "a1cf4fe7-d260-4662-9d49-5bc205bbc2b6"
      },
      "id": "LzJQcSbY8PQH",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
            "Model saved successfully as GradientBoostingRegressor_GridSearch.pkl\n",
            "GradientBoostingRegressor\n",
            "Best parameters found:  {'learning_rate': 0.01, 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
            "Mean Squared Error: 0.9202898325203462\n",
            "Root Mean Squared Error: 0.9593173784104748\n",
            "Mean Absolute Error: 0.6559298555060051\n",
            "R^2 Score: 0.9683504138271524\n",
            "File GradientBoostingRegressor_GridSearch.pkl exists.\n",
            "File size: 14138413 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **XGB Regressor**"
      ],
      "metadata": {
        "id": "Jx4oMiSfMeX6"
      },
      "id": "Jx4oMiSfMeX6"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "import pickle as pkl\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Setting up cross-validation and model parameters\n",
        "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "xgbr = XGBRegressor(random_state=42)\n",
        "PARAMETERS_xgb = {\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.01, 0.1, 0.3],\n",
        "    \"min_child_weight\": [1, 3, 5],\n",
        "    \"n_estimators\": [100, 500, 1000],\n",
        "    \"gamma\": [0, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "# Performing grid search with cross-validation\n",
        "model_gs = GridSearchCV(xgbr, param_grid=PARAMETERS_xgb, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=2)\n",
        "model_gs.fit(Xtrain, Ytrain)\n",
        "\n",
        "# Saving the model\n",
        "model_filename = 'XGBRegressor_GridSearch.pkl'\n",
        "try:\n",
        "    with open(model_filename, 'wb') as file:\n",
        "        pkl.dump(model_gs, file)\n",
        "    print(f\"Model saved successfully as {model_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the model: {e}\")\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model_gs.predict(Xtest)\n",
        "\n",
        "# Printing regression metrics\n",
        "print(model_gs.best_estimator_.__class__.__name__)\n",
        "print(\"Best parameters found: \", model_gs.best_params_)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(Ytest, y_pred))\n",
        "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(Ytest, y_pred)))\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error(Ytest, y_pred))\n",
        "print(\"R^2 Score:\", r2_score(Ytest, y_pred))\n",
        "\n",
        "# Verifying if the file was created\n",
        "if os.path.exists(model_filename):\n",
        "    print(f\"File {model_filename} exists.\")\n",
        "    print(f\"File size: {os.path.getsize(model_filename)} bytes\")\n",
        "else:\n",
        "    print(f\"File {model_filename} does not exist.\")"
      ],
      "metadata": {
        "id": "TAHLYagvCqqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6538531b-e336-46f6-be42-c6b219ceb090"
      },
      "id": "TAHLYagvCqqI",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
            "Model saved successfully as XGBRegressor_GridSearch.pkl\n",
            "XGBRegressor\n",
            "Best parameters found:  {'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 500}\n",
            "Mean Squared Error: 0.9520910446135606\n",
            "Root Mean Squared Error: 0.9757515281123369\n",
            "Mean Absolute Error: 0.6537314648417104\n",
            "R^2 Score: 0.9672567418479795\n",
            "File XGBRegressor_GridSearch.pkl exists.\n",
            "File size: 1014167 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **RandomForest Regressor**"
      ],
      "metadata": {
        "id": "V5w0inGoM_rk"
      },
      "id": "V5w0inGoM_rk"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pickle as pkl\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Setting up cross-validation and model parameters\n",
        "cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "rfr = RandomForestRegressor(random_state=42)\n",
        "PARAMETERS_rf = {\n",
        "    \"max_depth\": [5, 10, None],\n",
        "    \"n_estimators\": [100, 300, 500],\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "}\n",
        "\n",
        "# Performing grid search with cross-validation\n",
        "model_gs = GridSearchCV(rfr, param_grid=PARAMETERS_rf, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=2)\n",
        "model_gs.fit(Xtrain, Ytrain)\n",
        "\n",
        "# Saving the model\n",
        "model_filename = 'RandomForestRegressor_GridSearch.pkl'\n",
        "try:\n",
        "    with open(model_filename, 'wb') as file:\n",
        "        pkl.dump(model_gs, file)\n",
        "    print(f\"Model saved successfully as {model_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the model: {e}\")\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model_gs.predict(Xtest)\n",
        "\n",
        "# Printing regression metrics\n",
        "print(model_gs.best_estimator_.__class__.__name__)\n",
        "print(\"Best parameters found: \", model_gs.best_params_)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(Ytest, y_pred))\n",
        "print(\"Root Mean Squared Error:\", np.sqrt(mean_squared_error(Ytest, y_pred)))\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error(Ytest, y_pred))\n",
        "print(\"R^2 Score:\", r2_score(Ytest, y_pred))\n",
        "\n",
        "# Verifying if the file was created\n",
        "if os.path.exists(model_filename):\n",
        "    print(f\"File {model_filename} exists.\")\n",
        "    print(f\"File size: {os.path.getsize(model_filename)} bytes\")\n",
        "else:\n",
        "    print(f\"File {model_filename} does not exist.\")"
      ],
      "metadata": {
        "id": "odV48slnENiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e60182-d745-4b77-b5f1-f5027bc5554e"
      },
      "id": "odV48slnENiV",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "Model saved successfully as RandomForestRegressor_GridSearch.pkl\n",
            "RandomForestRegressor\n",
            "Best parameters found:  {'max_depth': None, 'max_features': None, 'n_estimators': 500}\n",
            "Mean Squared Error: 0.946689551747332\n",
            "Root Mean Squared Error: 0.972979728333192\n",
            "Mean Absolute Error: 0.6098482505867845\n",
            "R^2 Score: 0.9674425039936544\n",
            "File RandomForestRegressor_GridSearch.pkl exists.\n",
            "File size: 150170726 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training again on the best model**"
      ],
      "metadata": {
        "id": "Q7wXFNErayX6"
      },
      "id": "Q7wXFNErayX6"
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "import pickle as pkl\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import os\n",
        "\n",
        "# Assuming Xtrain and Ytrain are already defined\n",
        "\n",
        "# Create and fit the scaler\n",
        "scaler = StandardScaler()\n",
        "Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
        "Xtest_scaled = scaler.transform(Xtest)\n",
        "\n",
        "# Save the scaler\n",
        "scaler_filename = 'scaler.pkl'\n",
        "try:\n",
        "    with open(scaler_filename, 'wb') as file:\n",
        "        pkl.dump(scaler, file)\n",
        "    print(f\"Scaler saved successfully as {scaler_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the scaler: {e}\")\n",
        "\n",
        "# Create the best XGBoost model with the optimal parameters\n",
        "best_xgb_model = XGBRegressor(\n",
        "    learning_rate=0.03,\n",
        "    max_depth=6,\n",
        "    n_estimators=1000,\n",
        "    min_child_weight=1,\n",
        "    random_state=42  # for reproducibility\n",
        ")\n",
        "\n",
        "# Fit the model on the scaled training data\n",
        "best_xgb_model.fit(Xtrain_scaled, Ytrain)\n",
        "\n",
        "# Save the model\n",
        "best_model_filename = 'Best_XGBRegressor.pkl'\n",
        "try:\n",
        "    with open(best_model_filename, 'wb') as file:\n",
        "        pkl.dump(best_xgb_model, file)\n",
        "    print(f\"Best model saved successfully as {best_model_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving the best model: {e}\")\n",
        "\n",
        "# Verify if the files were created\n",
        "for filename in [scaler_filename, best_model_filename]:\n",
        "    if os.path.exists(filename):\n",
        "        print(f\"File {filename} exists.\")\n",
        "        print(f\"File size: {os.path.getsize(filename)} bytes\")\n",
        "    else:\n",
        "        print(f\"File {filename} does not exist.\")\n",
        "\n",
        "# Evaluate the best model on the scaled test set\n",
        "y_pred_best = best_xgb_model.predict(Xtest_scaled)\n",
        "\n",
        "# Calculate and print metrics\n",
        "mse = mean_squared_error(Ytest, y_pred_best)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(Ytest, y_pred_best)\n",
        "r2 = r2_score(Ytest, y_pred_best)\n",
        "\n",
        "print(\"\\nBest XGBoost Model Performance:\")\n",
        "print(f\"Root Mean Square Error: {rmse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUurb8gSa2kM",
        "outputId": "3e866f8d-faab-4698-c5e1-2b6488727c56"
      },
      "id": "lUurb8gSa2kM",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaler saved successfully as scaler.pkl\n",
            "Best model saved successfully as Best_XGBRegressor.pkl\n",
            "File scaler.pkl exists.\n",
            "File size: 617 bytes\n",
            "File Best_XGBRegressor.pkl exists.\n",
            "File size: 3857687 bytes\n",
            "\n",
            "Best XGBoost Model Performance:\n",
            "Root Mean Square Error: 0.9680660367741918\n",
            "Mean Absolute Error: 0.6505846630660513\n",
            "R^2 Score: 0.9677705139894612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing with players_22 data**"
      ],
      "metadata": {
        "id": "wHHKGCaQWYH2"
      },
      "id": "wHHKGCaQWYH2"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the new data\n",
        "players = pd.read_csv('/content/drive/My Drive/players_22.csv') #df with Columns: 110 entries)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kAhhFaaWevi",
        "outputId": "d0ba950f-81e2-418e-8303-ec3362f4ad49"
      },
      "id": "0kAhhFaaWevi",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-a50ce2352cba>:4: DtypeWarning: Columns (25,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  players = pd.read_csv('/content/drive/My Drive/players_22.csv') #df with Columns: 110 entries)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the columns that are in df but not in new_data\n",
        "columns_to_keep = [col for col in df.columns if col in players.columns]\n",
        "\n",
        "# Keep only these columns in new_data\n",
        "players = players[columns_to_keep]"
      ],
      "metadata": {
        "id": "N90dwRjaZH-E"
      },
      "id": "N90dwRjaZH-E",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "players = impute_missing_values(players)"
      ],
      "metadata": {
        "id": "zdUolAOCygAa"
      },
      "id": "zdUolAOCygAa",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Extract 'preferred_foot' values and encode them\n",
        "values = np.array(players['preferred_foot'])\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "\n",
        "# Drop the original 'preferred_foot' column\n",
        "players.drop('preferred_foot', axis=1, inplace=True)\n",
        "\n",
        "# Add the integer encoded 'preferred_foot' column back to the DataFrame\n",
        "players['preferred_foot'] = integer_encoded"
      ],
      "metadata": {
        "id": "dezctCfw4s29"
      },
      "id": "dezctCfw4s29",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare features (X) and target (y) for the new data\n",
        "X = players.drop(['overall'], axis=1)\n",
        "y = players['overall']"
      ],
      "metadata": {
        "id": "gxZJmtolXkAP"
      },
      "id": "gxZJmtolXkAP",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_scaled = sc.fit_transform(X)"
      ],
      "metadata": {
        "id": "FXSl8_gICXyi"
      },
      "id": "FXSl8_gICXyi",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "URsfP7378Kqb"
      },
      "id": "URsfP7378Kqb",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgb_model.fit(Xtrain, Ytrain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "YWVDKl5RC0DL",
        "outputId": "051b436b-e429-4d29-f3b5-c57023de5d27"
      },
      "id": "YWVDKl5RC0DL",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
              "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
              "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
              "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=1000, n_jobs=None,\n",
              "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_predictions = best_xgb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "MLFxm3qtW9Bb"
      },
      "id": "MLFxm3qtW9Bb",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test, xgb_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test, xgb_predictions)\n",
        "r2 = r2_score(y_test, xgb_predictions)\n",
        "\n",
        "print(f\"\\nResults for XGBoost:\")\n",
        "print(f\"Root Mean Square Error: {rmse}\")\n",
        "print(f\"Mean Absolute Error: {mae}\")\n",
        "print(f\"R2 Score: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7hGOHm0W-EK",
        "outputId": "4efbd5b2-6147-464b-8b79-e283b1f48f74"
      },
      "id": "S7hGOHm0W-EK",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for XGBoost:\n",
            "Root Mean Square Error: 3.8821185360368173\n",
            "Mean Absolute Error: 2.839441850626543\n",
            "R2 Score: 0.6779605277557514\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Djkhy6z4BOyT"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}